{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Important Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo_clean</th>\n",
       "      <th>amount</th>\n",
       "      <th>category_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>KROGER</td>\n",
       "      <td>20.98</td>\n",
       "      <td>GROCERIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>CASH APP * FREE CA</td>\n",
       "      <td>200.00</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>AMAZON * AMZN WA</td>\n",
       "      <td>33.20</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>AMAZON</td>\n",
       "      <td>42.79</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>KROGER</td>\n",
       "      <td>36.55</td>\n",
       "      <td>GROCERIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prism_consumer_id prism_account_id          memo_clean  amount  \\\n",
       "0                   0            acc_0              KROGER   20.98   \n",
       "1                   0            acc_0  CASH APP * FREE CA  200.00   \n",
       "7                   0            acc_0    AMAZON * AMZN WA   33.20   \n",
       "9                   0            acc_0              AMAZON   42.79   \n",
       "10                  0            acc_0              KROGER   36.55   \n",
       "\n",
       "   category_description  \n",
       "0             GROCERIES  \n",
       "1   GENERAL_MERCHANDISE  \n",
       "7   GENERAL_MERCHANDISE  \n",
       "9   GENERAL_MERCHANDISE  \n",
       "10            GROCERIES  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('data/data_clean.pqt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data for Baseline Text Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>memo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GROCERIES</td>\n",
       "      <td>KROGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>CASH APP * FREE CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>AMAZON * AMZN WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>AMAZON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GROCERIES</td>\n",
       "      <td>KROGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category                memo\n",
       "0             GROCERIES              KROGER\n",
       "1   GENERAL_MERCHANDISE  CASH APP * FREE CA\n",
       "7   GENERAL_MERCHANDISE    AMAZON * AMZN WA\n",
       "9   GENERAL_MERCHANDISE              AMAZON\n",
       "10            GROCERIES              KROGER"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['category_description', 'memo_clean']]\n",
    "data = data.rename(columns = {'category_description':'category', 'memo_clean':'memo'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EDUCATION': 0,\n",
       " 'FOOD_AND_BEVERAGES': 1,\n",
       " 'GENERAL_MERCHANDISE': 2,\n",
       " 'GROCERIES': 3,\n",
       " 'MORTGAGE': 4,\n",
       " 'OVERDRAFT': 5,\n",
       " 'PETS': 6,\n",
       " 'RENT': 7,\n",
       " 'TRAVEL': 8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = data['category'].unique()\n",
    "categories.sort()\n",
    "cat_dict = dict(zip(categories, np.arange(len(categories))))\n",
    "cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>memo</th>\n",
       "      <th>category_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GROCERIES</td>\n",
       "      <td>KROGER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>CASH APP * FREE CA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>AMAZON * AMZN WA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>AMAZON</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GROCERIES</td>\n",
       "      <td>KROGER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category                memo  category_label\n",
       "0             GROCERIES              KROGER               3\n",
       "1   GENERAL_MERCHANDISE  CASH APP * FREE CA               2\n",
       "7   GENERAL_MERCHANDISE    AMAZON * AMZN WA               2\n",
       "9   GENERAL_MERCHANDISE              AMAZON               2\n",
       "10            GROCERIES              KROGER               3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category_label'] = data['category'].map(cat_dict)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>memo</th>\n",
       "      <th>category_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>MLT SCHOOL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>CREATIVE LEARNING P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>POS W UNIVERSITY MESA AZ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>UGA GA CTR RESTAURAQPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>PURCHASE AUTHORIZED ON SCHOOL TOOLS EAST FAYET...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                               memo  \\\n",
       "0  EDUCATION                                         MLT SCHOOL   \n",
       "1  EDUCATION                                CREATIVE LEARNING P   \n",
       "2  EDUCATION                           POS W UNIVERSITY MESA AZ   \n",
       "3  EDUCATION                             UGA GA CTR RESTAURAQPS   \n",
       "4  EDUCATION  PURCHASE AUTHORIZED ON SCHOOL TOOLS EAST FAYET...   \n",
       "\n",
       "   category_label  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced = data.groupby('category').apply(lambda x: x.sample(1000, replace=True)).reset_index(drop=True)\n",
    "data_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_balanced[['memo']], data_balanced['category_label'], test_size=0.2, random_state=707)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=707)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing BERT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BERT_MODEL = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, X, y, tokenizer, max_length):\n",
    "        super(BertDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.tokenizer = tokenizer\n",
    "        self.y = y\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.X.iloc[index,0]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            pad_to_max_length=True,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length'\n",
    "        )\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'target': torch.tensor(self.y.iloc[index], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "\n",
    "dataset_train = BertDataset(X_train, y_train, tokenizer, max_length=20)\n",
    "dataloader_train = DataLoader(dataset=dataset_train,batch_size=32)\n",
    "\n",
    "dataset_valid = BertDataset(X_valid, y_valid, tokenizer, max_length=20)\n",
    "dataloader_valid = DataLoader(dataset=dataset_valid,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_base = BertForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL,\n",
    "    num_labels=len(cat_dict),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "epochs = 3\n",
    "\n",
    "#Initialize Optimizer\n",
    "optimizer= optim.Adam(bert_base.parameters(),lr= 1e-5,eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(dataloader_train)*epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in cat_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val, model):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader_train, dataloader_validation, scheduler, model, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # print(batch.keys())\n",
    "            # batch = tuple(b.to(device) for b in batch)\n",
    "            \n",
    "            inputs = {\n",
    "                'input_ids':    batch['ids'],\n",
    "                'attention_mask': batch['mask'],\n",
    "                'labels':         batch['target'],\n",
    "            }       \n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            progress_bar.set_description(f'Epoch={epoch}/{epochs}')\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "\n",
    "            \n",
    "            \n",
    "        torch.save(model.state_dict(), f'models/finetuned_BERT_epoch_{epoch}.model')\n",
    "            \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "        \n",
    "        loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "        \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory data_volume does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/darrenjiang/Desktop/UG Files/Year 4/4.1/DSC 180A/DSC_180A/model_testing.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/darrenjiang/Desktop/UG%20Files/Year%204/4.1/DSC%20180A/DSC_180A/model_testing.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m bert_base \u001b[39m=\u001b[39m train(dataloader_train, dataloader_valid, scheduler, bert_base, epochs)\n",
      "\u001b[1;32m/Users/darrenjiang/Desktop/UG Files/Year 4/4.1/DSC 180A/DSC_180A/model_testing.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darrenjiang/Desktop/UG%20Files/Year%204/4.1/DSC%20180A/DSC_180A/model_testing.ipynb#X63sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     progress_bar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch=\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darrenjiang/Desktop/UG%20Files/Year%204/4.1/DSC%20180A/DSC_180A/model_testing.ipynb#X63sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     progress_bar\u001b[39m.\u001b[39mset_postfix({\u001b[39m'\u001b[39m\u001b[39mtraining_loss\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(loss\u001b[39m.\u001b[39mitem()\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(batch))})\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/darrenjiang/Desktop/UG%20Files/Year%204/4.1/DSC%20180A/DSC_180A/model_testing.ipynb#X63sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m torch\u001b[39m.\u001b[39;49msave(model\u001b[39m.\u001b[39;49mstate_dict(), \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata_volume/finetuned_BERT_epoch_\u001b[39;49m\u001b[39m{\u001b[39;49;00mepoch\u001b[39m}\u001b[39;49;00m\u001b[39m.model\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darrenjiang/Desktop/UG%20Files/Year%204/4.1/DSC%20180A/DSC_180A/model_testing.ipynb#X63sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m tqdm\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darrenjiang/Desktop/UG%20Files/Year%204/4.1/DSC%20180A/DSC_180A/model_testing.ipynb#X63sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m loss_train_avg \u001b[39m=\u001b[39m loss_train_total\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(dataloader_train)            \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dsc180/lib/python3.9/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dsc180/lib/python3.9/site-packages/torch/serialization.py:492\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     container \u001b[39m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 492\u001b[0m \u001b[39mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dsc180/lib/python3.9/site-packages/torch/serialization.py:463\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39mPyTorchFileWriter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_stream))\n\u001b[1;32m    462\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileWriter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory data_volume does not exist."
     ]
    }
   ],
   "source": [
    "bert_base = train(dataloader_train, dataloader_valid, scheduler, bert_base, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
