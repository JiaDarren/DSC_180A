{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Important Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data'\n",
    "MODEL_PATH = '../../src/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo</th>\n",
       "      <th>amount</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>category</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>TST CASA DEL RIO EXP FAIRLAWN OH</td>\n",
       "      <td>18.42</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>BUFFALO WILD WINGS</td>\n",
       "      <td>26.47</td>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>OCULUS CA</td>\n",
       "      <td>11.73</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>LOS GIRASOLES STOW OH</td>\n",
       "      <td>30.04</td>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>BUZZIS LAUNDRY OH</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prism_consumer_id prism_account_id                              memo  \\\n",
       "2                  0            acc_0  TST CASA DEL RIO EXP FAIRLAWN OH   \n",
       "4                  0            acc_0                BUFFALO WILD WINGS   \n",
       "6                  0            acc_0                         OCULUS CA   \n",
       "7                  0            acc_0             LOS GIRASOLES STOW OH   \n",
       "8                  0            acc_0                 BUZZIS LAUNDRY OH   \n",
       "\n",
       "   amount posted_date             category  year  month  day  \n",
       "2   18.42  2022-09-26   FOOD_AND_BEVERAGES  2022      9   26  \n",
       "4   26.47  2022-09-12   FOOD_AND_BEVERAGES  2022      9   12  \n",
       "6   11.73  2022-04-18  GENERAL_MERCHANDISE  2022      4   18  \n",
       "7   30.04  2022-03-09   FOOD_AND_BEVERAGES  2022      3    9  \n",
       "8    4.16  2022-03-29  GENERAL_MERCHANDISE  2022      3   29  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(f'{DATA_PATH}/processed/data_clean.pqt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data for Baseline Text Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>memo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>TST CASA DEL RIO EXP FAIRLAWN OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>BUFFALO WILD WINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>OCULUS CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>LOS GIRASOLES STOW OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>BUZZIS LAUNDRY OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category                              memo\n",
       "2   FOOD_AND_BEVERAGES  TST CASA DEL RIO EXP FAIRLAWN OH\n",
       "4   FOOD_AND_BEVERAGES                BUFFALO WILD WINGS\n",
       "6  GENERAL_MERCHANDISE                         OCULUS CA\n",
       "7   FOOD_AND_BEVERAGES             LOS GIRASOLES STOW OH\n",
       "8  GENERAL_MERCHANDISE                 BUZZIS LAUNDRY OH"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['category', 'memo']]\n",
    "# data = data.rename(columns = {'category_description':'category', 'memo_clean':'memo'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EDUCATION': 0,\n",
       " 'FOOD_AND_BEVERAGES': 1,\n",
       " 'GENERAL_MERCHANDISE': 2,\n",
       " 'GROCERIES': 3,\n",
       " 'MORTGAGE': 4,\n",
       " 'OVERDRAFT': 5,\n",
       " 'PETS': 6,\n",
       " 'RENT': 7,\n",
       " 'TRAVEL': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = data['category'].unique()\n",
    "categories.sort()\n",
    "cat_dict = dict(zip(categories, np.arange(len(categories))))\n",
    "cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0_/tww2_mb540ldlyk4js_q8l8r0000gn/T/ipykernel_94283/1358508834.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['category_label'] = data['category'].map(cat_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>memo</th>\n",
       "      <th>category_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>TST CASA DEL RIO EXP FAIRLAWN OH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>BUFFALO WILD WINGS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>OCULUS CA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>LOS GIRASOLES STOW OH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>BUZZIS LAUNDRY OH</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category                              memo  category_label\n",
       "2   FOOD_AND_BEVERAGES  TST CASA DEL RIO EXP FAIRLAWN OH               1\n",
       "4   FOOD_AND_BEVERAGES                BUFFALO WILD WINGS               1\n",
       "6  GENERAL_MERCHANDISE                         OCULUS CA               2\n",
       "7   FOOD_AND_BEVERAGES             LOS GIRASOLES STOW OH               1\n",
       "8  GENERAL_MERCHANDISE                 BUZZIS LAUNDRY OH               2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category_label'] = data['category'].map(cat_dict)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>memo</th>\n",
       "      <th>category_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>EDUCATIONAL EPAYMENT MORENO MONICA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>POS DEBIT VISA CHECK CARD TEACHERSPAYTEACHER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>CHECKCARD ICP * GOLDFISH SWIM SCHOO CO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>PURCHASE AUTHORIZED ON MSB DENVER PUBLIC CO CARD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>OREGON SCHOOL F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                              memo  category_label\n",
       "0  EDUCATION                EDUCATIONAL EPAYMENT MORENO MONICA               0\n",
       "1  EDUCATION      POS DEBIT VISA CHECK CARD TEACHERSPAYTEACHER               0\n",
       "2  EDUCATION            CHECKCARD ICP * GOLDFISH SWIM SCHOO CO               0\n",
       "3  EDUCATION  PURCHASE AUTHORIZED ON MSB DENVER PUBLIC CO CARD               0\n",
       "4  EDUCATION                                   OREGON SCHOOL F               0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced = data.groupby('category').apply(lambda x: x.sample(1000, replace=True)).reset_index(drop=True)\n",
    "data_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_balanced[['memo']], data_balanced['category_label'], test_size=0.2, random_state=707)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=707)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing BERT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BERT_MODEL = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, X, y, tokenizer, max_length):\n",
    "        super(BertDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.tokenizer = tokenizer\n",
    "        self.y = y\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.X.iloc[index,0]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            pad_to_max_length=True,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length'\n",
    "        )\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'target': torch.tensor(self.y.iloc[index], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "\n",
    "dataset_train = BertDataset(X_train, y_train, tokenizer, max_length=20)\n",
    "dataloader_train = DataLoader(dataset=dataset_train,batch_size=32)\n",
    "\n",
    "dataset_valid = BertDataset(X_valid, y_valid, tokenizer, max_length=20)\n",
    "dataloader_valid = DataLoader(dataset=dataset_valid,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_base = BertForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL,\n",
    "    num_labels=len(cat_dict),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "epochs = 3\n",
    "\n",
    "#Initialize Optimizer\n",
    "optimizer= optim.Adam(bert_base.parameters(),lr= 1e-5,eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(dataloader_train)*epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in cat_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val, model):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(batch[b].to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[3],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader_train, dataloader_validation, scheduler, model, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # print(batch.keys())\n",
    "            batch = tuple(batch[b].to(device) for b in batch)\n",
    "            \n",
    "            inputs = {\n",
    "                'input_ids':    batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':         batch[3],\n",
    "            }       \n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            progress_bar.set_description(f'Epoch={epoch}/{epochs}')\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "\n",
    "            \n",
    "            \n",
    "        torch.save(model.state_dict(), f'{MODEL_PATH}/BERT_Baseline_epoch_{epoch}.model')\n",
    "            \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "        \n",
    "        loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "        \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_validation, model)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "Training loss: 1.641977694299486\n",
      "Validation loss: 0.9374385529094272\n",
      "F1 Score (Weighted): 0.7873632723016488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.7395104580455356\n",
      "Validation loss: 0.537149167060852\n",
      "F1 Score (Weighted): 0.8661026731058772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.5071926216284434\n",
      "Validation loss: 0.4719823853837119\n",
      "F1 Score (Weighted): 0.8783513233172373\n"
     ]
    }
   ],
   "source": [
    "bert_base = train(dataloader_train, dataloader_valid, scheduler, bert_base, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing BERT Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = BertDataset(X_test, y_test, tokenizer, max_length=20)\n",
    "dataloader_test = DataLoader(dataset=dataset_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val_avg, predictions, true_vals = evaluate(dataloader_test, bert_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_cats = np.array([np.argmax(pred) for pred in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of BERT Baseline with 3 Epochs: 0.8816666666666667\n"
     ]
    }
   ],
   "source": [
    "acc = sum(prediction_cats == true_vals) / true_vals.shape[0]\n",
    "print(f\"Overall accuracy of BERT Baseline with {epochs} Epochs: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
