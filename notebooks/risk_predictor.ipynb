{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from functools import reduce\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = pd.read_parquet(f'{DATA_PATH}/raw/q2_consDF_final.pqt')\n",
    "acct = pd.read_parquet(f'{DATA_PATH}/raw/q2_acctDF_final.pqt')\n",
    "inflows = pd.read_parquet(f'{DATA_PATH}/raw/q2_inflows_final.pqt')\n",
    "outflows = pd.read_parquet(f'{DATA_PATH}/raw/q2_outflows_final.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Balance at time of evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_var = acct[['prism_consumer_id','balance','balance_date']].groupby('prism_consumer_id').agg({\n",
    "    'balance':['min', 'max', 'std'],\n",
    "    'balance_date':['max']\n",
    "}).reset_index()\n",
    "balance_var.fillna(0.0, inplace=True)\n",
    "\n",
    "balance_var.columns = balance_var.columns.to_flat_index().map(lambda x: x[1] + x[0])\n",
    "features.append(balance_var)\n",
    "balance_var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disposable Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_eval_dates = cons.sort_values('evaluation_date')[['prism_consumer_id','evaluation_date']]\n",
    "outflow_merged = pd.merge(outflows, cons_eval_dates, on=\"prism_consumer_id\", how=\"left\")\n",
    "inflow_merged = pd.merge(inflows, cons_eval_dates, on=\"prism_consumer_id\", how=\"left\")\n",
    "outflow_merged['amount'] = outflow_merged['amount'] * -1\n",
    "total_balance = pd.concat([inflow_merged, outflow_merged])\n",
    "\n",
    "total_balance = total_balance[total_balance['posted_date'] <= total_balance['evaluation_date']]\n",
    "\n",
    "total_balance = total_balance[[\n",
    "        'prism_consumer_id',\n",
    "        'amount',\n",
    "        'posted_date',\n",
    "]].groupby('prism_consumer_id').agg({'amount':['sum'],'posted_date':['min','max']})\n",
    "\n",
    "total_balance['date_range'] = pd.to_timedelta(total_balance['posted_date','max'] - total_balance['posted_date','min']).dt.days / 365\n",
    "total_balance = pd.DataFrame({\n",
    "    'total_balance': total_balance['amount','sum'] / total_balance['date_range'], \n",
    "    'total_balance_date': total_balance['posted_date', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "features.append(total_balance)\n",
    "total_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow_valid = outflow_merged[outflow_merged['posted_date'] <= outflow_merged['evaluation_date']]\n",
    "outflow_counts = outflow_valid.groupby('prism_consumer_id').agg({\n",
    "    'amount':['count'],\n",
    "    'posted_date':['min','max'],\n",
    "}).reset_index()\n",
    "\n",
    "outflow_counts['date_range'] = pd.to_timedelta(outflow_counts['posted_date','max'] - outflow_counts['posted_date','min']).dt.days / 365 * 12\n",
    "\n",
    "outflow_counts = pd.DataFrame({\n",
    "    'prism_consumer_id': outflow_counts['prism_consumer_id'],\n",
    "    'num_monthly_purchase': outflow_counts['amount','count'] / outflow_counts['date_range'],\n",
    "})\n",
    "\n",
    "outflow_counts.replace([np.inf, -np.inf], 0.0, inplace=True)\n",
    "features.append(outflow_counts)\n",
    "outflow_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Savings Feature - count of how many times someone has pulled from savings account**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_from_savings = inflows[inflows['category_description']=='SELF_TRANSFER']\n",
    "transfer_from_savings = transfer_from_savings[transfer_from_savings['memo_clean'].str.contains('Savings')]\n",
    "count_tfs = transfer_from_savings.groupby('prism_consumer_id').count().reset_index()\n",
    "inflow_ids = pd.merge(inflows[['prism_consumer_id']], count_tfs, on='prism_consumer_id', how='left')\n",
    "inflow_ids = inflow_ids.fillna(0).drop_duplicates(subset=['prism_consumer_id']).reset_index()[['prism_consumer_id', 'memo_clean']]\n",
    "inflow_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all features into feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = reduce(\n",
    "    lambda left,right: pd.merge(left,right, on='prism_consumer_id', how='outer'), \n",
    "    features\n",
    ")\n",
    "\n",
    "feature_dates = re.findall(r\"\\w+_date\", str(list(feature_df.columns)))\n",
    "feature_df['feature_date'] = feature_df[feature_dates].max(axis=1)\n",
    "feature_df.drop(feature_dates, axis=1, inplace=True)\n",
    "feature_df.fillna(0.0, inplace=True)\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype Model to Predict Default Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cons = cons.sort_values('evaluation_date')\n",
    "\n",
    "dropped_cols = ['prism_consumer_id', 'evaluation_date', 'feature_date']\n",
    "feature_matrix = pd.merge(sorted_cons, feature_df, on='prism_consumer_id', how='left')\n",
    "\n",
    "# Make sure no invalid training data is pulled\n",
    "assert np.mean(feature_matrix['evaluation_date'] < feature_matrix['feature_date']) == 0, \"Features pulled from dates after evaluation_date\"\n",
    "feature_matrix.drop(dropped_cols, axis=1, inplace=True)\n",
    "\n",
    "# Train Test Split\n",
    "TRAIN_SPLIT = 0.75\n",
    "train = feature_matrix.iloc[:int(feature_matrix.shape[0] * TRAIN_SPLIT)].drop(\"APPROVED\", axis=1)\n",
    "test = feature_matrix.iloc[int(feature_matrix.shape[0] * TRAIN_SPLIT):].drop(\"APPROVED\", axis=1)\n",
    "\n",
    "X_train = train.iloc[:,1:]\n",
    "y_train = train.iloc[:,0]\n",
    "X_test = test.iloc[:,1:]\n",
    "y_test = test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "cm_train = confusion_matrix(y_train, train_pred)\n",
    "cm_test = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "tn_train, fp_train, fn_train, tp_train = cm_train.ravel()\n",
    "tn_test, fp_test, fn_test, tp_test = cm_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Accuracy: {np.mean(model.predict(X_train) == y_train):.4f}\")\n",
    "print(f\"Testing Accuracy: {np.mean(model.predict(X_test) == y_test):.4f}\")\n",
    "print(\"Coefficients: \\n\", model.coef_, \"\\n\")\n",
    "\n",
    "print(f\"tn_train: {tn_train}, fp_train: {fp_train}, fn_train: {fn_train}, tp_train: {tp_train}\")\n",
    "print(f\"tn_test:  {tn_test},  fp_test:  {fp_test},  fn_test:  {fn_test}, tp_test:  {tp_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
